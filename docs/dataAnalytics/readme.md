# **Data Analytics** <a href="../"><img src="../../assets/atomicBi.png" alt="Business intelligence" align="right" height="64px"></a>
L’analytique des données répond à des besoins spécifiques en matière d’informatique décisionnelle (e.g. : prévoir le résultat de décisions commerciales, générer des rapports et des tableaux de bord, réduire l’inefficacité opérationnelle, et cætera).

## **Qu’est-ce que c’est ?**
L’analytique des données convertit les données brutes en informations exploitables. Comprenant une gamme d’outils, de technologies et de processus utilisés pour identifier des tendances et résoudre des problèmes en utilisant des données. L’analyse des données peut façonner les processus d’affaires, améliorer la prise de décision et favoriser la croissance de l’entreprise.
## **Pourquoi est-elle importante ?**
Permettant aux entreprises de gagner en visibilité et d’obtenir une compréhension plus approfondie de leurs processus et services, elle leur offre des informations détaillées de l’expérience et les problèmes des clients. En dépassant le paradigme des données pour connecter les informations et l’action, les entreprises peuvent créer des expériences client personnalisées, concevoir des produits numériques connexes, optimiser les opérations et améliorer la productivité des employés.
## **Qu’est-ce que l’analytique big data ?**
Le big data fait référence à de grands jeux de données diverses (structurées, non structurées et semi-structurées) qui sont générées de manière continue à grande vitesse et à volume élevé. En général, le big data se mesure en téraoctets ou en pétaoctets. Un pétaoctet équivaut à 1 000 000 gigaoctets. Pour remettre cela en perspective, imaginez qu’un seul film en HD contient environ 4 gigaoctets de données. Un pétaoctet est équivalent à 250 000 films. Les grands jeux de données mesurent des centaines, des milliers, voire des millions de pétaoctets.

L’analytique du big data est le processus de découverte de modèles, de tendances et de relations au sein de jeux de données énormes. Cette analytique complexe nécessite des outils et des technologies spécifiques, une puissance de calcul et un stockage de données qui prennent en charge l’échelle.
## **Qu’est-ce que l’analytique big data ?**
Il s’agit de très grands jeux de données diverses (structurées ou non voire semi-structurées) générées continuellement à grande vitesse et à volume élevé. En général, le big data se mesure en téraoctets ou en pétaoctets. Un pétaoctet équivaut à 1 000 000 gigaoctets. Un pétaoctet est équivalent à 250 000 films. Les grands jeux de données mesurent des centaines, des milliers, voire des millions de pétaoctets.

L’analytique du big data est le processus de découverte de modèles, de tendances et de relations au sein de jeux de données énormes. Cette analytique complexe nécessite des outils et technologies spécifiques, une puissance de calcul et un stockage de données prenant en charge l’échelle.

Cf. [Comment fonctionne l’analytique du Big Data](analBigData)

## **Les techniques d’analytique des données**
De nombreuses techniques de calcul sont utilisées en analytique des données. En voici certaines des plus répandues :
* **Le traitement du langage naturel**  
  La technologie utilisée afin que les ordinateurs comprennent et répondent au langage humain parlé et écrit. Les analystes de données utilisent cette technique pour traiter des données telles que les notes dictées, les commandes vocales et les messages de chat.
* **L’exploration de texte**  
  Les analystes de données l’utilisent pour identifier les tendances des données textuelles comme les e-mails, les tweets, les recherches et les billets de blog. Elle peut être utilisée pour trier du contenu informationnel, des commentaires client et des e-mails des client.
* **L’analyse de données de capteurs**  
  C’est l’examen des données générées par différents capteurs. Elle est utilisée pour la maintenance des machines prédictives, le suivi des expéditions et d’autres processus métier dans le cadre desquels des machines génèrent des données.
* **L’analyse des valeurs aberrantes**  
  Aussi nommée _détection des anomalies_, identifie les points de données et les événements qui dévient du reste des données.
## **Son autimatisation**
Les analystes de données peuvent automatiser et optimiser Ces processus. L’analytique automatisée des données consiste à utiliser des systèmes informatiques afin d’effectuer des tâches analytiques avec peu ou sans l’intervention humaine. Ces mécanismes varient en complexité. Ils vont des scripts ou lignes de code simples, aux outils d’analytique des données qui réalisent la modélisation de données, la découverte de fonctions et l’analyse statistique (une entreprise de cybersécurité peut utiliser l’automatisation pour rassembler des données provenant de larges pans de l’activité Web, faire une analyse approfondie et utiliser la visualisation de données afin d’exposer les résultats et appuyer les décisions métier).
## **Son externalisation**
Cela permet à l’équipe de gestion et de direction de se concentrer sur d’autres opérations essentielles de l’activité. Les équipes d’analytique métier dédiées sont expertes en leur domaine, connaissent les dernières techniques d’analytique des données et, sont spécialistes de la gestion de données. Leur analyse de données plus efficace, et ça améliore l’identification des tendances et les prédictions des futures tendances. Néanmoins, le transfert des connaissances et la confidentialité des données sont un risque.
___
>>> Sujet connexe  
[Comment fonctionne l’analytique du Big Data](analBigData)  
>
>>> Source  
[Amazon Web Services](https://aws.amazon.com/fr/what-is/data-analytics/)